{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "id": "pi1tN5X8n38K"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1) Model creation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "id": "tzGoSgDdiqKw"
   },
   "outputs": [],
   "source": [
    "def create_node():\n",
    "    \"\"\"\n",
    "    Function that returns a dictionary representing a node\n",
    "\n",
    "    feature_index: the feature of the data the node is going to split\n",
    "    threhsold: the value to split\n",
    "    is_final: boolean indicating whether or not the node is a leaf\n",
    "    label: the label we have to return if the node is a leaf\n",
    "    child_true: the tree we go on if we condition based on the feature_index and the threhsold is verified\n",
    "    child_false: the tree we go otherwise\n",
    "    indicies: the indicies of X_train that go through this node\n",
    "    current_depth: current depth of the node in the tree\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    dico = {'feature_index': None,\n",
    "            'threshold': None,\n",
    "            'is_final': False,\n",
    "            'label': None,\n",
    "            'child_true': {},\n",
    "            'child_false': {},\n",
    "            'indicies': [],\n",
    "            'current_depth': None\n",
    "            }\n",
    "      \n",
    "    return dico\n",
    "\n",
    "\n",
    "def get_proportions(y, nb_labels):\n",
    "    proportions = [0 for i in range(nb_labels)]\n",
    "    n = len(y)\n",
    "    \n",
    "    if n > 0:\n",
    "        for i in range(nb_labels):\n",
    "            proportions[i] = len(np.nonzero(y == i)[0]) / n\n",
    "\n",
    "        return proportions\n",
    "\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "\n",
    "def compute_criterion(type='gini', y=[], nb_labels=2):\n",
    "    n = len(y)\n",
    "\n",
    "    if n > 0:\n",
    "        proportions = get_proportions(y, nb_labels)\n",
    "        \n",
    "        res = 0\n",
    "        \n",
    "        for i in range(nb_labels):\n",
    "            if type == 'gini':\n",
    "                res += (proportions[i]*(1 - proportions[i]))\n",
    "\n",
    "            elif type == 'entropy' or type == 'log_loss':\n",
    "                if proportions[i] != 0:\n",
    "                    res -= proportions[i]*np.log(proportions[i])\n",
    "                    \n",
    "            else:\n",
    "                raise Exception(\"The criterion you specified does not exist or is not implemented yet\")\n",
    "\n",
    "        return res\n",
    "    \n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "id": "Uq2zKeC2oHBD"
   },
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, criterion='gini', max_depth=None, min_samples_split=2, max_features=None):\n",
    "        self.tree = {}\n",
    "        self.criterion = criterion\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_features = max_features\n",
    "\n",
    "    def __call__(self, X):\n",
    "        return self.predict(X)\n",
    "\n",
    "    def compute_max_features(self, nb_features):\n",
    "        if self.max_features == None:\n",
    "            self.max_features = nb_features\n",
    "            \n",
    "        elif isinstance(self.max_features, int):\n",
    "            try:\n",
    "                assert (self.max_features > 0) and (self.max_features <= nb_features)\n",
    "            except:\n",
    "                raise Exception(\"The number of features to consider when splitting must be contained between 0 and the number of features of X_train\")\n",
    "        \n",
    "        elif isinstance(self.max_features, float):\n",
    "            self.max_features = max(1, int(self.max_features * nb_features))\n",
    "            try:\n",
    "                assert (self.max_features > 0) and (self.max_features <= nb_features)\n",
    "            except:\n",
    "                raise Exception(\"The ratio of features to consider when splitting must be contained between 0 and 1\")\n",
    "            \n",
    "        elif self.max_features == \"sqrt\":\n",
    "            self.max_features = max(1, np.floor(np.sqrt(nb_features)))\n",
    "        \n",
    "        elif self.max_features == \"log2\":\n",
    "            self.max_features = max(1, np.floor(np.log2(nb_features)))\n",
    "        \n",
    "        elif self.max_features == \"auto\":\n",
    "            self.max_features = max(1, np.floor(np.sqrt(nb_features)))\n",
    "            \n",
    "    def fit(self, X, y):\n",
    "        X = X.to_numpy()\n",
    "        y = y.to_numpy()\n",
    "\n",
    "        n, nb_features = X.shape\n",
    "        nb_labels = np.max(y)\n",
    "        \n",
    "        # Gestion de max_features\n",
    "        self.compute_max_features(nb_features)\n",
    "\n",
    "        # On initialise l'arbre à un noeud\n",
    "        root = create_node()\n",
    "        root['indicies'] = np.arange(n)\n",
    "        root['current_depth'] = 1\n",
    "\n",
    "        # On initialise la pile de noeuds\n",
    "        to_compute = [root]\n",
    "\n",
    "        # Tant qu'il reste un noeud à traiter\n",
    "        while (to_compute):\n",
    "            # On récupère le dernier élément de to_compute et on le retire\n",
    "            node = to_compute.pop()\n",
    "\n",
    "            # On récupère les lignes du dataset qui correspondent à notre noeud\n",
    "            indicies = node['indicies']\n",
    "            X_tronq = X[indicies]\n",
    "            y_tronq = y[indicies]\n",
    "            nb_samples = len(y_tronq)\n",
    "\n",
    "            # On vérifie s'il n'y a qu'une seule classe\n",
    "            if len(np.unique(y_tronq)) == 1:\n",
    "                # S'il n'y a qu'une classe, le noeud est une feuille\n",
    "                node['is_final'] = True\n",
    "                node['label'] = y_tronq[0]\n",
    "                \n",
    "            elif len(indicies) < self.min_samples_split:\n",
    "                label = np.argmax(get_proportions(indicies, nb_labels=nb_labels))\n",
    "                node['is_final'] = True\n",
    "                node['label'] = label\n",
    "            \n",
    "            else:\n",
    "                # Sinon, s'il y a plusieurs classes\n",
    "                # On stocke la valeur max du critère et les indices correspondant\n",
    "                min_criterion = np.inf\n",
    "                feature_index = None\n",
    "                threshold = None\n",
    "                found_criterion = False\n",
    "\n",
    "                # On sélectionne les features à checker (choisies de manière aléatoire avec self.max_features)\n",
    "                features_to_check = [i for i in range(nb_features)]\n",
    "                random.seed(random.randint(0, 100))\n",
    "                random.shuffle(features_to_check)\n",
    "                features_to_check = features_to_check[:self.max_features]\n",
    "\n",
    "                for i in features_to_check:\n",
    "                    # On récupère les valeurs possibles\n",
    "                    possible_values = np.unique(X_tronq[:, i])\n",
    "                    possible_values = np.sort(possible_values)\n",
    "\n",
    "                    if len(possible_values) >= 2:\n",
    "                        possible_values = possible_values[1:]\n",
    "                        found_criterion = True\n",
    "                        \n",
    "                        \"\"\"il faudrait optimiser le calcul des proportions pour chaque valeur, car actuellement la complexité est en O(n²)\n",
    "                        alors qu'on peut faire du O(n)\"\"\"\n",
    "                        # Pour chaque valeur\n",
    "                        for value in possible_values:\n",
    "                            # On récupère les indices où la valeur de la feature est inférieure\n",
    "                            lower_indexes = np.nonzero(X_tronq[:, i] < value)[0]\n",
    "                            # Et les indices où la valeur est supérierue ou égale\n",
    "                            greater_indexes = np.nonzero(X_tronq[:, i] >= value)[0]\n",
    "\n",
    "                            # On récupère les labels correspondant\n",
    "                            y_lower = y_tronq[lower_indexes]\n",
    "                            y_greater = y_tronq[greater_indexes]\n",
    "\n",
    "                            # On calcule les critères\n",
    "                            criterion_lower = compute_criterion(self.criterion, y_lower, nb_labels=nb_labels)\n",
    "                            criterion_greater = compute_criterion(self.criterion, y_greater, nb_labels=nb_labels)\n",
    "\n",
    "                            # On calcule le critère final\n",
    "                            nb_samples_lower = len(y_lower)\n",
    "                            nb_samples_greater = len(y_greater)\n",
    "                           \n",
    "                            criterion_split = nb_samples_lower/nb_samples*criterion_lower + nb_samples_greater/nb_samples*criterion_greater\n",
    "\n",
    "                            if (criterion_split < min_criterion):\n",
    "                                min_criterion = criterion_split\n",
    "                                feature_index = i\n",
    "                                threshold = value\n",
    "                \n",
    "                \n",
    "                new_depth = node['current_depth'] + 1\n",
    "                \n",
    "                if found_criterion:\n",
    "                    # On met à jour les informations du noeud\n",
    "                    node['feature_index'] = feature_index\n",
    "                    node['threshold'] = threshold\n",
    "                    node['is_final'] = False\n",
    "                    \n",
    "                    # On récupère les indices pour le noeud où la condition est vérifiée\n",
    "                    true_index = np.nonzero(X_tronq[:, feature_index] < threshold)[0]\n",
    "                    # Pareil pour le noeud où la condition n'est pas vérifiée\n",
    "                    false_index = np.nonzero(X_tronq[:, feature_index] >= threshold)[0]\n",
    "\n",
    "                    # On crée les enfants du noeud, et on met leurs indices\n",
    "                    child_true = create_node()\n",
    "                    child_true['indicies'] = indicies[true_index]\n",
    "                    child_true['current_depth'] = new_depth\n",
    "\n",
    "                    child_false = create_node()\n",
    "                    child_false['indicies'] = indicies[false_index]\n",
    "                    child_false['current_depth'] = new_depth\n",
    "\n",
    "                    node['child_true'] = child_true\n",
    "                    node['child_false'] = child_false\n",
    "\n",
    "                    # On les ajoute à la pile\n",
    "                    if self.max_depth and (new_depth < self.max_depth):\n",
    "                        to_compute.append(child_true)\n",
    "                        to_compute.append(child_false)\n",
    "\n",
    "                    else:\n",
    "                        label_true = np.argmax(get_proportions(indicies[true_index], nb_labels=nb_labels))\n",
    "                        label_false = np.argmax(get_proportions(indicies[false_index], nb_labels=nb_labels))\n",
    "\n",
    "                        child_true['label'] = label_true\n",
    "                        child_true['is_final'] = True\n",
    "                        child_false['label'] = label_false\n",
    "                        child_false['is_final'] = True\n",
    "                        \n",
    "                else:\n",
    "                    label = np.argmax(get_proportions(indicies, nb_labels=nb_labels))\n",
    "                    node['is_final'] = True\n",
    "                    node['label'] = label\n",
    "                    \n",
    "        self.tree = root\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = X.to_numpy()\n",
    "\n",
    "        res = []\n",
    "        for i in range(len(X)):\n",
    "            res.append(self.predict_one(X[i]))\n",
    "        \n",
    "        return np.array(res)\n",
    "\n",
    "    \n",
    "    def predict_one(self, x):\n",
    "        current_node = self.tree\n",
    "\n",
    "        while not current_node['is_final']:\n",
    "            threshold = current_node['threshold']\n",
    "            feature_index = current_node['feature_index']\n",
    "            if x[feature_index] < threshold:\n",
    "                current_node = current_node['child_true']\n",
    "            else:\n",
    "                current_node = current_node['child_false']\n",
    "\n",
    "        return current_node['label']\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "56Koc4AboAl-"
   },
   "source": [
    "# **2) Load dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JcG9idAepCmn"
   },
   "source": [
    "Creation of a dataset that contains weight and size for adults (label 1) and children (label 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "jzbmomCWoAF3",
    "outputId": "7adf4349-beea-4ffe-ffa0-8977657dfe7a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obj_ID</th>\n",
       "      <th>alpha</th>\n",
       "      <th>delta</th>\n",
       "      <th>u</th>\n",
       "      <th>g</th>\n",
       "      <th>r</th>\n",
       "      <th>i</th>\n",
       "      <th>z</th>\n",
       "      <th>run_ID</th>\n",
       "      <th>rerun_ID</th>\n",
       "      <th>cam_col</th>\n",
       "      <th>field_ID</th>\n",
       "      <th>spec_obj_ID</th>\n",
       "      <th>class</th>\n",
       "      <th>redshift</th>\n",
       "      <th>plate</th>\n",
       "      <th>MJD</th>\n",
       "      <th>fiber_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.237661e+18</td>\n",
       "      <td>135.689107</td>\n",
       "      <td>32.494632</td>\n",
       "      <td>23.87882</td>\n",
       "      <td>22.27530</td>\n",
       "      <td>20.39501</td>\n",
       "      <td>19.16573</td>\n",
       "      <td>18.79371</td>\n",
       "      <td>3606</td>\n",
       "      <td>301</td>\n",
       "      <td>2</td>\n",
       "      <td>79</td>\n",
       "      <td>6.543777e+18</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.634794</td>\n",
       "      <td>5812</td>\n",
       "      <td>56354</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.237665e+18</td>\n",
       "      <td>144.826101</td>\n",
       "      <td>31.274185</td>\n",
       "      <td>24.77759</td>\n",
       "      <td>22.83188</td>\n",
       "      <td>22.58444</td>\n",
       "      <td>21.16812</td>\n",
       "      <td>21.61427</td>\n",
       "      <td>4518</td>\n",
       "      <td>301</td>\n",
       "      <td>5</td>\n",
       "      <td>119</td>\n",
       "      <td>1.176014e+19</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.779136</td>\n",
       "      <td>10445</td>\n",
       "      <td>58158</td>\n",
       "      <td>427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.237661e+18</td>\n",
       "      <td>142.188790</td>\n",
       "      <td>35.582444</td>\n",
       "      <td>25.26307</td>\n",
       "      <td>22.66389</td>\n",
       "      <td>20.60976</td>\n",
       "      <td>19.34857</td>\n",
       "      <td>18.94827</td>\n",
       "      <td>3606</td>\n",
       "      <td>301</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>5.152200e+18</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.644195</td>\n",
       "      <td>4576</td>\n",
       "      <td>55592</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.237663e+18</td>\n",
       "      <td>338.741038</td>\n",
       "      <td>-0.402828</td>\n",
       "      <td>22.13682</td>\n",
       "      <td>23.77656</td>\n",
       "      <td>21.61162</td>\n",
       "      <td>20.50454</td>\n",
       "      <td>19.25010</td>\n",
       "      <td>4192</td>\n",
       "      <td>301</td>\n",
       "      <td>3</td>\n",
       "      <td>214</td>\n",
       "      <td>1.030107e+19</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.932346</td>\n",
       "      <td>9149</td>\n",
       "      <td>58039</td>\n",
       "      <td>775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.237680e+18</td>\n",
       "      <td>345.282593</td>\n",
       "      <td>21.183866</td>\n",
       "      <td>19.43718</td>\n",
       "      <td>17.58028</td>\n",
       "      <td>16.49747</td>\n",
       "      <td>15.97711</td>\n",
       "      <td>15.54461</td>\n",
       "      <td>8102</td>\n",
       "      <td>301</td>\n",
       "      <td>3</td>\n",
       "      <td>137</td>\n",
       "      <td>6.891865e+18</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.116123</td>\n",
       "      <td>6121</td>\n",
       "      <td>56187</td>\n",
       "      <td>842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         obj_ID       alpha      delta         u         g         r  \\\n",
       "0  1.237661e+18  135.689107  32.494632  23.87882  22.27530  20.39501   \n",
       "1  1.237665e+18  144.826101  31.274185  24.77759  22.83188  22.58444   \n",
       "2  1.237661e+18  142.188790  35.582444  25.26307  22.66389  20.60976   \n",
       "3  1.237663e+18  338.741038  -0.402828  22.13682  23.77656  21.61162   \n",
       "4  1.237680e+18  345.282593  21.183866  19.43718  17.58028  16.49747   \n",
       "\n",
       "          i         z  run_ID  rerun_ID  cam_col  field_ID   spec_obj_ID  \\\n",
       "0  19.16573  18.79371    3606       301        2        79  6.543777e+18   \n",
       "1  21.16812  21.61427    4518       301        5       119  1.176014e+19   \n",
       "2  19.34857  18.94827    3606       301        2       120  5.152200e+18   \n",
       "3  20.50454  19.25010    4192       301        3       214  1.030107e+19   \n",
       "4  15.97711  15.54461    8102       301        3       137  6.891865e+18   \n",
       "\n",
       "    class  redshift  plate    MJD  fiber_ID  \n",
       "0  GALAXY  0.634794   5812  56354       171  \n",
       "1  GALAXY  0.779136  10445  58158       427  \n",
       "2  GALAXY  0.644195   4576  55592       299  \n",
       "3  GALAXY  0.932346   9149  58039       775  \n",
       "4  GALAXY  0.116123   6121  56187       842  "
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"star_classification.csv\") # Récupérer sur https://www.kaggle.com/datasets/fedesoriano/stellar-classification-dataset-sdss17\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "id": "bc7J-Ev76o0G"
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=['obj_ID'])\n",
    "dico = {'GALAXY': 0, 'QSO': 1, 'STAR': 2}\n",
    "df['class'] = df['class'].apply(lambda s: dico[s])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Re-cYzTEoHZ7"
   },
   "source": [
    "# **3) Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "id": "WOCs7p6VpjbW"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = df.drop(columns=['class'])\n",
    "y = df['class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "457R9cycp_Ed"
   },
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(criterion='gini', max_depth=1, min_samples_split=2, max_features=3)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "id": "xy8u7uGm5t_G"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9814814814814815\n",
      "0.42857142857142855\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_train)\n",
    "print(\"Training score : \", accuracy_score(preds, y_train))\n",
    "\n",
    "preds = model.predict(X_test)\n",
    "print(\"Testing score : \", accuracy_score(preds, y_test))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
