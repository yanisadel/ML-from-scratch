{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b64b9a72",
   "metadata": {},
   "source": [
    "# **Reinforcement learning : Puissance 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3144711",
   "metadata": {},
   "source": [
    "Le but de ce script est d'implémenter un agent capable de jouer au jeu Puissance 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f4c5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cc8bc3",
   "metadata": {},
   "source": [
    "# 1) Création de l'environnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294593f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game:\n",
    "    \"\"\"\n",
    "    Class that describes a game being played\n",
    "    \"\"\"\n",
    "    def __init__(self, nb_rows=6, nb_columns=7, nb_players=2):\n",
    "        self.nb_rows = nb_rows\n",
    "        self.nb_columns = nb_columns\n",
    "        self.nb_players = nb_players\n",
    "        self.grid = np.zeros((nb_rows, nb_columns))\n",
    "        self.turn = 0\n",
    "        self.nb_steps = 0 # Total number of steps in the game\n",
    "        \n",
    "    def is_draw(self):\n",
    "        return self.nb_steps == nb_rows*nb_columns\n",
    "        \n",
    "    def is_legal(self, column):\n",
    "        # Takes as input a column and return whether it is possible or not to put a token or the column (True or False)\n",
    "        col_values = self.grid[:, column]\n",
    "        non_zeros, = np.where(col_values == 0)\n",
    "        return not (len(non_zeros) == 0)\n",
    "    \n",
    "    def set_token(self, column):\n",
    "        # Takes as input a column, and in the move is legal, put a token in the column\n",
    "        try:\n",
    "            assert self.is_legal(column)\n",
    "        except:\n",
    "            raise Exception(\"The move is not legal. Column {} is already filled\".format(column))\n",
    "        \n",
    "        row_index = np.where(self.grid[:, column] == 0)[0][0]\n",
    "        player_token = 1\n",
    "        if self.turn == 1:\n",
    "            player_token = -1\n",
    "            \n",
    "        self.grid[row_index][column] = player_token\n",
    "        \n",
    "        self.turn = (self.turn + 1) % self.nb_players\n",
    "        self.nb_steps += 1\n",
    "        \n",
    "    def won(self, player_id):\n",
    "        # Return True if the player n°player_id won, False otherwise\n",
    "        token_player = 1\n",
    "        if player_id == 1:\n",
    "            token_player = -1\n",
    "            \n",
    "        for row in range(self.nb_rows):\n",
    "            for column in range(self.nb_columns):\n",
    "                current_token = self.grid[row][column]\n",
    "                if current_token == token_player:\n",
    "                    token_array = token_player*np.ones(3)\n",
    "                    \n",
    "                    if np.array_equal(self.grid[row-3:row, column], token_array):\n",
    "                        return True\n",
    "                    \n",
    "                    elif np.array_equal(self.grid[row, column-3:column], token_array):\n",
    "                        return True\n",
    "                    \n",
    "                    elif np.array_equal(self.grid[row-3:row, column-3:column].diagonal(), token_array):\n",
    "                        return True\n",
    "                    \n",
    "        return False\n",
    "    \n",
    "    def get_observation(self):\n",
    "        # Returns the observation that the agent makes\n",
    "        return self.grid\n",
    "    \n",
    "    def render(self):\n",
    "        # Displays the current state of the game\n",
    "        X = []\n",
    "        Y = []\n",
    "        colors = []\n",
    "        color_player1 = np.array([210, 200, 0]) / 255\n",
    "        color_player2 = np.array([255, 0, 0]) / 255\n",
    "        for row in range(self.nb_rows):\n",
    "            for col in range(self.nb_rows):\n",
    "                token = self.grid[row, col]\n",
    "                if token == 1 or token == -1:\n",
    "                    Y.append(row)\n",
    "                    X.append(col)\n",
    "                    \n",
    "                    if token == 1:\n",
    "                        colors.append(color_player1)\n",
    "                    elif token == -1:\n",
    "                        colors.append(color_player2)\n",
    "                    \n",
    "        plt.scatter(X, Y, color=colors, s=600)\n",
    "        plt.xticks(list(range(-1, self.nb_columns+2)))\n",
    "        plt.yticks(list(range(-1, self.nb_rows+2)))\n",
    "        plt.grid()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c867964a",
   "metadata": {},
   "outputs": [],
   "source": [
    "game = Game()\n",
    "\n",
    "game.set_token(0)\n",
    "game.set_token(1)\n",
    "game.set_token(0)\n",
    "game.set_token(0)\n",
    "game.set_token(2)\n",
    "game.set_token(3)\n",
    "game.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84d082b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Env:\n",
    "    \"\"\"\n",
    "    Class that represents the environment in which the agent is. \n",
    "    The agent is going to do multiple games in the environment\n",
    "    \"\"\"\n",
    "    def __init__(self, actions=[], nb_rows=6, nb_columns=7, nb_players=2):\n",
    "        self.nb_rows = nb_rows\n",
    "        self.nb_columns = nb_columns\n",
    "        self.nb_players = nb_players\n",
    "        self.game = Game(nb_rows=nb_rows, nb_columns=nb_columns, nb_players=nb_players)\n",
    "        self.winners = np.array([False, False])\n",
    "        self.actions = actions\n",
    "        \n",
    "    def step(self, action):\n",
    "        # Takes an action, which is the index of the column where we want to put a token in\n",
    "        observation = self.game.get_observation()\n",
    "        self.game.set_token(actions[action])\n",
    "        next_observation = self.game.get_observation()\n",
    "        reward = 0\n",
    "        game_finished = False\n",
    "        \n",
    "        if self.game.won(0):\n",
    "            self.winners[0] = True\n",
    "            reward = 1\n",
    "            game_finished = True\n",
    "            \n",
    "        elif self.game.won(1):\n",
    "            self.winners[1] = True\n",
    "            reward = -10\n",
    "            game_finished = True\n",
    "            \n",
    "        elif self.game.is_draw():\n",
    "            reward = -1\n",
    "            game_finished = True\n",
    "        \n",
    "        return observation, reward, next_observation, game_finished\n",
    "    \n",
    "    def reset(self):\n",
    "        self.game = Game(nb_rows=self.nb_rows, nb_columns=self.nb_columns, nb_players=self.nb_players)\n",
    "        self.winners = np.array([False, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8826bed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_rows = 6\n",
    "nb_columns = 7\n",
    "\n",
    "actions = np.arange(nb_columns)\n",
    "nb_actions = len(actions)\n",
    "\n",
    "env = Env(nb_rows=nb_rows, nb_columns=nb_columns, nb_players=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce7985a",
   "metadata": {},
   "source": [
    "# 2) On définit l'estimateur des valeurs d'actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff09a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d71bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(keras.Model):\n",
    "  def __init__(self, nb_rows=6, nb_columns=7, nb_actions=7):\n",
    "    super().__init__()\n",
    "    self.conv1 = layers.Conv2D(8, (3, 3), activation='relu', input_shape=(nb_rows, nb_columns, 1))\n",
    "    self.conv2 = layers.Conv2D(8, (2, 2), activation='relu')\n",
    "\n",
    "    self.flatten = layers.Flatten()\n",
    "    self.pooling = layers.MaxPooling2D((2,2))\n",
    "    self.dense1 = layers.Dense(32, activation='relu')\n",
    "    self.dense2 = layers.Dense(nb_actions)\n",
    "\n",
    "  def call(self, x):\n",
    "    x = tf.expand_dims(x, axis=-1)\n",
    "    x = self.conv1(x)\n",
    "    x = self.pooling(x)\n",
    "    x = self.conv2(x)\n",
    "    x = self.flatten(x)\n",
    "    x = self.dense1(x)\n",
    "    return self.dense2(x)\n",
    "\n",
    "model = MyModel()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
